{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2304fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, math\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.datasets as dsets\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140eddfd",
   "metadata": {},
   "source": [
    "## Fashion MNIST 进行分类\n",
    "### Fashion MNIST介绍\n",
    "\n",
    "Fashion MNIST数据集是kaggle上提供的一个图像分类入门级的数据集，其中包含10个类别的70000个灰度图像。如图所示，这些图片显示的是每件衣服的低分辨率(28×28像素)。`Fashion MNIST`的目标是作为经典MNIST数据的替换——通常被用作计算机视觉机器学习程序的“Hello, World”。\n",
    "\n",
    "### 数据集介绍\n",
    "#### 分类\n",
    "\n",
    "- 0 T-shirt/top\n",
    "- 1 Trouser\n",
    "- 2 Pullover\n",
    "- 3 Dress\n",
    "- 4 Coat\n",
    "- 5 Sandal\n",
    "- 6 Shirt\n",
    "- 7 Sneaker\n",
    "- 8 Bag\n",
    "- 9 Ankle boot \n",
    "\n",
    "#### 格式\n",
    "存储的训练的数据和测试的数据，格式如下：\n",
    "\n",
    "label是分类的标签 pixel1-pixel784是每一个像素代表的值。因为是灰度图像，所以是一个0-255之间的数值。\n",
    "\n",
    "为什么是784个像素？ 28 * 28 = 784\n",
    "\n",
    "#### 数据提交\n",
    "Fashion MNIST不需要我们进行数据的提交，数据集中已经帮助我们将 训练集和测试集分好了，我们只需要载入、训练、查看即可，所以Fashion MNIST 是一个非常好的入门级别的数据集。\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511ced30",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = Path('./data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e32233c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(DATA_PATH / \"fashion-minist_train.csv\")\n",
    "train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c9c50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(DATA_PATH / \"fashion-minist_test.csv\")\n",
    "test.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6401da74",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8019e538",
   "metadata": {},
   "outputs": [],
   "source": [
    "import struct\n",
    "from PIL import Image\n",
    "\n",
    "with open(DATA_PATH / \"train-images-idx3-ubyte\", \"rb\") as file_object:\n",
    "    header_data = struct.unpack(\">4I\", file_object.read(16))\n",
    "    print(header_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382c2a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(DATA_PATH / \"train-labels-idx1-ubyte\", \"rb\") as file_object:\n",
    "    header_data = struct.unpack(\">2I\", file_object.read(8))\n",
    "    print(header_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29830d45",
   "metadata": {},
   "source": [
    "有四字节的`header_data`，故使用`unpack_from`进行二进制转换时，偏置`offset=16`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bdbf1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(DATA_PATH / \"train-images-idx3-ubyte\", \"rb\") as file_object:\n",
    "    raw_img = file_object.read()\n",
    "\n",
    "img = struct.unpack_from(\">784B\", raw_img, 16)\n",
    "image = np.asarray(img).reshape(28, 28)\n",
    "print(image.shape)\n",
    "plt.imshow(image, cmap = plt.cm.gray)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6d9004",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(DATA_PATH / \"train-labels-idx1-ubyte\", \"rb\") as file_object:\n",
    "    raw_img = file_object.read(1)\n",
    "    label = struct.unpack(\">B\", raw_img)\n",
    "    print(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa538814",
   "metadata": {},
   "source": [
    "### 数据加载\n",
    "为了使用`pytorch`的`dataloader`进行数据的加载，需要先创建一个自定义的`dataset`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0ce5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FashionMNISTDataset(Dataset):\n",
    "    def __init__(self, csv_file, transform = None):\n",
    "        data = pd.read_csv(csv_file)\n",
    "        self.X = np.array(data.iloc[:, 1:]).reshape(-1, 1, 28, 28).astype(float)\n",
    "        self.Y = np.array(data.iloc[:, 0]);\n",
    "\n",
    "        del data; # 释放内存\n",
    "        self.len = len(self.X)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = self.X[idx]\n",
    "        label = self.Y[idx]\n",
    "        return (item, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1617fad6",
   "metadata": {},
   "source": [
    "对于自定义的数据集，只需要实现三个函数：\n",
    "\n",
    "`__init__`:初始化函数主要用于数据的加载，这里直接使用`pandas`将数据读取为`dataframe`，然后将其转成`numpy`数组来进行索引。\n",
    "\n",
    "`__len__`:返回数据集的总数，`pytorch`里面的`dataloader`需要知道数据集的总数\n",
    "\n",
    "`__getitem__`:会返回单张图片，它包含一个`index`，返回值为样本及其标签\n",
    "\n",
    "\n",
    "## 创建和训练测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2f0413",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = FashionMNISTDataset(csv_file = DATA_PATH / \"fashion-mnist_train.csv\")\n",
    "test_dataset = FashionMNISTDataset(csv_file = DATA_PATH / \"fashion-mnist_test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b9d86e",
   "metadata": {},
   "source": [
    "在使用Pytorch的DataLoader读取数据之前，需要指定一个batch size这也是一个超参数，涉及到内存的使用量，如果出现OOM的错误则要减小这个数值，一般这个数值都为2的幂或者2的倍数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9069968a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#因为是常量，所以大写，需要说明的是，这些常量建议都使用完整的英文单词，减少歧义\n",
    "BATCH_SIZE = 256 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0fa072a",
   "metadata": {},
   "source": [
    "我们接着使用`dataloader`模块来使用这些数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19fda7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset = train_dataset, batch_size = BATCH_SIZE, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748efabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import shuffle\n",
    "\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset = test_dataset, batch_size = BATCH_SIZE, shuffle = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c21afc6",
   "metadata": {},
   "source": [
    "查看一下数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f759f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = iter(train_loader)\n",
    "data = next(a)\n",
    "img = data[0][0].reshape(28, 28)\n",
    "data[0][0].shape, img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a888b891",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img, cmap = plt.cm.gray)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9d8162",
   "metadata": {},
   "source": [
    "### 创建网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23de505",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size = 5, padding = 2),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, kernel_size = 3),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size = 3),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "        self.fc = nn.Linear(5 * 5 * 64, 10)\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.pool1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.pool2(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9cabb45",
   "metadata": {},
   "source": [
    "在函数里使用`torch.nn`提供的模块来定义各个层，在每个卷积层后使用了批次的归一化和RELU激活并且在每一个操作分组后面进行了pooling的操作（减少信息量，避免过拟合），后我们使用了全连接层来输出10个类别。\n",
    "\n",
    "`view`函数用来改变输出值矩阵的形状来匹配最后一层的维度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57bc45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = CNN();\n",
    "cnn(torch.rand(1, 1, 28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf28dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd53fc3",
   "metadata": {},
   "source": [
    "从定义模型开始就要指定模型计算的位置，CPU还是GPU，所以需要加另外一个参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed197f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cpu\")\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = torch.device(\"cuda\")\n",
    "\n",
    "print(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf77e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = cnn.to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0807e0e0",
   "metadata": {},
   "source": [
    "### 损失函数\n",
    "多分类因为使用`Softmax`回归将神经网络前向传播得到的结果变成概率分布 所以使用交叉熵损失。 \n",
    "\n",
    "在`pytorch`中`NN.CrossEntropyLoss`是将`nn.LogSoftmax()`和`nn.NLLLoss()`进行了整合，`CrossEntropyLoss`,我们也可以分开来写使用两步计算，这里为了方便直接一步到位。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28bb3eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#损失函数也需要放到GPU中\n",
    "criterion = nn.CrossEntropyLoss().to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c6d47fb",
   "metadata": {},
   "source": [
    "### 优化器\n",
    "Adam优化器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b7558c",
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 0.01 # 学习率\n",
    "optimizer = torch.optim.Adam(cnn.parameters(), lr = LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6775c37",
   "metadata": {},
   "source": [
    "### 开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fae3e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOTAL_EPOCHS = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e9eed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "losses = [];\n",
    "for epoch in range(TOTAL_EPOCHS):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images.float().to(DEVICE)\n",
    "        labels = labels.to(DEVICE)\n",
    "\n",
    "        # 梯度清零\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 前向传播\n",
    "        outputs = cnn(images)\n",
    "        \n",
    "        # 计算损失\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # 反向传播\n",
    "        loss.backward()\n",
    "\n",
    "        # 更新参数\n",
    "        optimizer.step()\n",
    "\n",
    "        # 记录损失\n",
    "        losses.append(loss.cpu().data.item());\n",
    "\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print('Epoch: %d%d, Iter: %d%d, Loss: %.4f' % (epoch + 1, TOTAL_EPOCHS, \n",
    "            i + 1, len(train_loader) // BATCH_SIZE, loss.data.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59998bbd",
   "metadata": {},
   "source": [
    "### 可视化损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc2c24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xkcd();\n",
    "plt.xlabel('Epoch #');\n",
    "plt.ylabel('Loss');\n",
    "plt.plot(losses);\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cfc5ae0",
   "metadata": {},
   "source": [
    "### 保存模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f6a6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(cnn.state_dict(), \"fm-cnn3.pth\")\n",
    "# 加载用这个\n",
    "#cnn.load_state_dict(torch.load(\"fm-cnn3.pth\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21463f79",
   "metadata": {},
   "source": [
    "### 模型评估\n",
    "模型评估就是使用测试集对模型进行的评估，应该是添加到训练中进行了，这里为了方便说明直接在训练完成后评估了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f3f4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "for images, labels in test_loader:\n",
    "    images = images.float().to(DEVICE)\n",
    "    outputs = cnn(images).cpu()\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum()\n",
    "\n",
    "print('Accuracy: %.4f %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c1492b9",
   "metadata": {},
   "source": [
    "模型评估的步骤如下：\n",
    "\n",
    "1. 将网络的模式改为eval。\n",
    "2. 将图片输入到网络中得到输出。\n",
    "3. 通过取出one-hot输出的最大值来得到输出的 标签。\n",
    "4. 统计正确的预测值。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca84a4d",
   "metadata": {},
   "source": [
    "### 进一步优化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441b1d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# 修改学习率和批次\n",
    "cnn.train()\n",
    "LEARNING_RATE = LEARNING_RATE * 0.1\n",
    "TOTAL_EPOCHS = 20\n",
    "optimizer = torch.optim.Adam(cnn.parameters(), lr = 0.001)\n",
    "losses = [];\n",
    "\n",
    "for epoch in range(TOTAL_EPOCHS):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images.float().to(DEVICE)\n",
    "        labes = labels.to(DEVICE)\n",
    "\n",
    "        # 梯度清零\n",
    "        optimizer.zero_grad()\n",
    "        outputs = cnn(images)\n",
    "\n",
    "        # 计算损失\n",
    "        loss = criterion(outputs, labels).cpu()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss.data.item())\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print('Epoch: %d%d, Iter: %d%d, Loss: %.4f' % (epoch + 1, TOTAL_EPOCHS, \n",
    "            i + 1, len(train_loader) // BATCH_SIZE, loss.data.item()))\n",
    "\n",
    "plt.xkcd();\n",
    "plt.xlabel('Epoch #');\n",
    "plt.ylabel('Loss');\n",
    "plt.plot(losses);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a05213",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ade138",
   "metadata": {},
   "source": [
    "### 再次进行评估\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f1dde2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "for images, labels in test_loader:\n",
    "    images = images.float().to(DEVICE)\n",
    "    outputs = cnn(images).cpu()\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum()\n",
    "\n",
    "print('Accuracy: %.4f %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70d8ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# 再次修改学习率和批次\n",
    "cnn.train()\n",
    "LEARNING_RATE = LEARNING_RATE * 0.1\n",
    "TOTAL_EPOCHS = 10\n",
    "optimizer = torch.optim.Adam(cnn.parameters(), lr = 0.001)\n",
    "losses = [];\n",
    "\n",
    "for epoch in range(TOTAL_EPOCHS):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images.float().to(DEVICE)\n",
    "        labels = labels.to(DEVICE)\n",
    "\n",
    "        # 梯度清零\n",
    "        optimizer.zero_grad()\n",
    "        outputs = cnn(images)\n",
    "\n",
    "        # 计算损失\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss.cpu().data.item());\n",
    "\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print('Epoch: %d%d, Iter: %d%d, Loss: %.4f' % (epoch + 1, TOTAL_EPOCHS, \n",
    "            i + 1, len(train_loader) // BATCH_SIZE, loss.data.item()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1988f675",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xkcd();\n",
    "plt.xlabel('Epoch #');\n",
    "plt.ylabel('Loss');\n",
    "plt.plot(losses);\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b880719b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "for images, labels in test_loader:\n",
    "    images = images.float().to(DEVICE)\n",
    "    outputs = cnn(images).cpu()\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum()\n",
    "print('Accuracy: %.4f %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7c3cd6",
   "metadata": {},
   "source": [
    "损失小了，但是准确率没有提高，这就说明已经接近模型的瓶颈了，如果再要进行优化，就需要修改模型了。另外还有一个判断模型是否到瓶颈的标准，就是看损失函数，最后一次的训练的损失函数明显的没有下降的趋势，只是在震荡，这说明已经没有什么优化的空间了。\n",
    "\n",
    "通过简单的操作，我们也能够看到Adam优化器的暴力性，我们只要简单的修改学习率就能够达到优化的效果，Adam优化器的使用一般情况下是首先使用0.1进行预热，然后再用0.01进行大批次的训练，最后使用0.001这个学习率进行收尾，再小的学习率一般情况就不需要了。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba11aba",
   "metadata": {},
   "source": [
    "## 总结\n",
    "最后总结几个超参数:\n",
    "\n",
    "`BATCH_SIZE`:批次数量，定义每次训练时多少数据作为一批，这个批次需要在dataloader初始化时进行设置，并且需要这对模型和显存进行配置，如果出现OOM有线减小，一般设为2的倍数\n",
    "\n",
    "`DEVICE`:进行计算的设备，主要是CPU还是GPU\n",
    "\n",
    "`LEARNING_RATE`:学习率，反向传播时使用\n",
    "\n",
    "`TOTAL_EPOCHS`: 训练的批次，一般情况下会根据损失和准确率等阈值"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f39e4d86",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
