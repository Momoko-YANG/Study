{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e254407",
   "metadata": {},
   "source": [
    "# 第二章 pandas基础"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "633363e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4bbc9d73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.3'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "069dba49",
   "metadata": {},
   "source": [
    "## 一、文件的读取和写入\n",
    "### 1. 文件读取\n",
    "\n",
    "`pandas`可以读取的文件格式有很多，这里主要介绍读取`csv`, `excel`, `txt`文件。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4b5378",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/my_csv.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m df_csv = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m../data/my_csv.csv\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\io\\parsers\\readers.py:912\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m    899\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m    900\u001b[39m     dialect,\n\u001b[32m    901\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m    908\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m    909\u001b[39m )\n\u001b[32m    910\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m--> \u001b[39m\u001b[32m912\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\io\\parsers\\readers.py:577\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    574\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    576\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m577\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    579\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    580\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\io\\parsers\\readers.py:1407\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1404\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1406\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1407\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\io\\parsers\\readers.py:1661\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1659\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1660\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1661\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1662\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1663\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1664\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1665\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1666\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1667\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1668\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1669\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1670\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1671\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1672\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\io\\common.py:859\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    854\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    855\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    856\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    857\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    858\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m859\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    860\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    861\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    862\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    863\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    864\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    865\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    866\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    867\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    868\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '../data/my_csv.csv'"
     ]
    }
   ],
   "source": [
    "df_csv = pd.read_csv('../data/my_csv.csv')\n",
    "df_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee49f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_txt = pd.read_table('../data/my_table.txt')\n",
    "df_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f92fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_excel = pd.read_excel('../data/my_excel.xlsx')\n",
    "df_excel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8caff0",
   "metadata": {},
   "source": [
    "这里有一些常用的公共参数，`header=None`表示第一行不作为列名，`index_col`表示把某一列或几列作为索引，`usecols`表示读取列的集合，默认读取所有的列，`parse_dates`表示需要转化为时间的列，`nrows`表示读取的数据行数。上面这些参数在上述的三个函数里都可以使用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc2e2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_table('../data/my_table.txt', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d3bcdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('../data/my_csv.csv', index_col=['col1', 'col2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a475a0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_table('../data/my_table.txt', usecols=['col1', 'col2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4f3b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('../data/my_csv.csv', parse_dates=['col5'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b142451",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_excel('../data/my_excel.xlsx', nrows=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4cb9de",
   "metadata": {},
   "source": [
    "在读取`txt`文件时，经常遇到分隔符非空格的情况，`read_table`有一个分割参数`sep`,它使得用户可以自定义分割符号，进行`txt`数据的读取。例如，下面的读取的表以`||||`为分割："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d966a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_table('../data/my_table_special_sep.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e6798c",
   "metadata": {},
   "source": [
    "上面的结果显然不是理想的，这时可以使用`sep`，同时需要指定引擎为`python`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed3d9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_table('../data/my_table_special_sep.txt', sep=' \\|\\|\\|\\| ', engine='python')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3cb451",
   "metadata": {},
   "source": [
    "#### 【WARNING】`sep`是正则参数\n",
    "在使用`read_table`的时候需要注意，参数`sep`中使用的是正则表达式，因此需要对`|`行转义变成`\\|`，否则无法读取到正确的结果。\n",
    "\n",
    "\n",
    "### 2. 数据写入\n",
    "一般在数据写入中，最常用的操作是把`index`设置为`False`,特别当索引没有特殊意义的时候，这样的行为能把索引在保存的时候去除。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd890591",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_csv.to_csv('../data/my_csv_saved.csv', index=False)\n",
    "df_excel.to_excel('../data/my_excel_saved.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e077e769",
   "metadata": {},
   "source": [
    "`pandas`中没有定义`to_table`函数，但是`to_csv`可以保存为`txt`文件，并且允许自定义分隔符，常用制表符`\\t`分割："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ad061e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_txt.to_csv('../data/my_txt_saved.txt', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b066aea1",
   "metadata": {},
   "source": [
    "如果想要把表格快速转换为`markdown`和`latex`语言，可以使用`to_markdown`和`to_latex`函数，此处需要安装`tabulate`包。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384a2b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_csv.to_markdown())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ff9fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_csv.to_latex())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a804f03d",
   "metadata": {},
   "source": [
    "## 二、基本数据结构\n",
    "`pandas`中具有两种基本的数据存储结构，存储一维`values`的`Series`和存储二维`values`的`DataFrame`，在这两种结构上定义了很多的属性和方法。\n",
    "\n",
    "### 1. Series\n",
    "`Series`一般由四个部分组成，分别是序列的值`data`、索引`index`、存储类型`dtype`、序列的名字`name`。其中，索引也可以指定它的名字，默认为空。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d64cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series(data=[100, 'a', {'dic1':5}],\n",
    "              index=pd.Index(['id1', 20, 'third'], name='my_idx'),\n",
    "              dtype='object',\n",
    "              name='my_name')\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640dd0dc",
   "metadata": {},
   "source": [
    "#### 【NOTE】`Object`类型\n",
    "`Object`代表了一种混合类型，正如上面的例子中存储了整数、字符串以及`Python`的字典数据结构。此外，目前`pandas`把纯字符串序列也默认认为是一种`Object`类型的序列，但它也可以用`string`类型存储，文本序列的内容会在第八章中讨论。\n",
    "\n",
    "对于这些属性，可以通过`.`的方式来获取："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862d380d",
   "metadata": {},
   "outputs": [],
   "source": [
    "s.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48b765b",
   "metadata": {},
   "outputs": [],
   "source": [
    "s.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20fa6008",
   "metadata": {},
   "outputs": [],
   "source": [
    "s.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf11677",
   "metadata": {},
   "outputs": [],
   "source": [
    "s.name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ffaca3",
   "metadata": {},
   "source": [
    "利用`.shape`可以获取序列的长度："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e99e91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "s.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9c0e12",
   "metadata": {},
   "source": [
    "索引是`pandas`中最重要的概念之一，如果想要取出单个索引对应的值，可以通过`[index_item]`可以取出。\n",
    "\n",
    "### 2. DataFrame\n",
    "`DataFrame`在`Series`的基础上增加了列索引，一个数据框可以由二维的`data`与行列索引来构造："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d517ab66",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [[1, 'a', 1.2], [2, 'b', 2.2], [3, 'c', 3.2]]\n",
    "df = pd.DataFrame(data=data,\n",
    "                  index = ['row_%d'%i for i in range(3)],\n",
    "                  columns=['col_0', 'col_1', 'col_2'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e68321",
   "metadata": {},
   "source": [
    "但一般而言，更多的时候会采用从列索引名到数据的映射来构造数据框，同时再加上行索引："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d7bad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data = {'col_0':[1, 2, 3],\n",
    "                          'col_1': list('abc'),\n",
    "                          'col_2':[1.2, 2.2, 3.2]},\n",
    "                          index = ['row_%d'%i for i in range(3)])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10be374f",
   "metadata": {},
   "source": [
    "由于这种映射关系，在`DateFrame`中可以用`[col_name]`与`[col_list]`来取出相应的列与由多个列组成的表，结果分别为`Series`和`DataFrame`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8939c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['col_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be85403",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['col_0', 'col_1']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b353679f",
   "metadata": {},
   "source": [
    "与`Series`类似，在数据框中同样可以取出相应的属性："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe32dcaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b5727e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0db7685",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14bf044e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes  # 返回的是值为相应列数据类型的Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f6f387",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f39282",
   "metadata": {},
   "source": [
    "通过`.T`可以把`DataFrame`进行转置："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0772bd36",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b84e74d",
   "metadata": {},
   "source": [
    "## 三、常用基本函数\n",
    "为了进行举例说明，在接下来的部分将会使用一份`learn_pandas.csv`的虚拟数据集，它记录了四所学校学生的体测个人信息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c35c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/learn_pandas.csv')\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "870fed55",
   "metadata": {},
   "source": [
    "上述列名依次代表学校、年级、姓名、性别、身高、体重、是否为转系生、体测场次、测试时间、1000米成绩，本章只需使用其中的前七列。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3906bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.columns[:7]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "786da192",
   "metadata": {},
   "source": [
    "### 1. 汇总函数\n",
    "`head`,`tail`函数分别表示返回表或者序列的前`n`行和后`n`行，其中`n`默认为5："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7de63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a5f506",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ced72c",
   "metadata": {},
   "source": [
    "`info`,`describe`分别返回表的信息概况和表中数值列对应的主要统计量："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b874c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce433df",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6654a0ea",
   "metadata": {},
   "source": [
    "#### 【NOTE】更全面的数据汇总\n",
    "`info`, `describe`只能实现较少信息的展示，如果想要对一份数据集进行全面且有效的观察，特别是在列较多的情况下，推荐使用`pandas-profiling`包\n",
    "\n",
    "\n",
    "### 2. 特征统计函数\n",
    "在`Series`和`DataFrame`上定义了许多统计函数，最常见的是`sum`, `mean`, `median`, `var`, `std`, `max`, `min`。例如，选出身高和体重列进行演示："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9007a096",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_demo = df[['Height', 'Weight']]\n",
    "df_demo.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a136d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_demo.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9673f6eb",
   "metadata": {},
   "source": [
    "此外，需要介绍的是`quantile`, `count`, `idxmax`这三个函数，它们分别返回的是分位数、非缺失值个数、最大值对应的索引："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "663725ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_demo.quantile(0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3432267",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_demo.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16e9077",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_demo.idxmax() # idxmin是对应的函数"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4fb8b74",
   "metadata": {},
   "source": [
    "上面这些所有的函数，由于操作后返回的是标量，所以又称为聚合函数，它们有一个公共参数axis，默认为0代表逐列聚合，如果设置为1则表示逐行聚合："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce8aefc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_demo.mean(axis=1).head()  # 在这个数据集上体重和身高的均值并没有意义"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b53e601",
   "metadata": {},
   "source": [
    "### 3. 唯一值函数\n",
    "对序列使用`unique`和`nunique`可以分别得到其唯一值组成的列表和唯一值的个数："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d852a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['School'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af74b94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['School'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb75099",
   "metadata": {},
   "source": [
    "`value_counts`可以得到唯一值和其对应出现的频数："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b093c446",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Schhol'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9bfb272",
   "metadata": {},
   "source": [
    "如果想要观察多个列组合的唯一值，可以使用`drop_duplicates`。其中的关键参数是`keep`，默认值`first`表示每个组合保留第一次出现的所在行，`last`表示保留最后一次出现的所在行，`False`表示把所有重复组合所在的行剔除。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56e51d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_demo = df[['Gender', 'Transfer', 'Name']]\n",
    "df_demo.drop_duplicates(['Gender', 'Transfer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca736e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_demo.drop_duplicates(['Gender', 'Transfer'], keep='last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746ef7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_demo.drop_duplicates(['Name', 'Gender'], keep=False).head()     # 保留只出现过一次的性别和姓名组合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a83c1966",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['School'].drop_duplicates()   # 在Series上也可以使用"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f1c707",
   "metadata": {},
   "source": [
    "此外，`duplicated`和`drop_duplicates`的功能类似，但前者返回了是否为唯一值的布尔列表，其`keep`参数与后者一致。其返回的序列，把重复元素设为`True`，否则为`False`。`drop_duplicates`等价于把`duplicated`为`True`的对应行剔除。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5ac35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_demo.duplicated(['Gender', 'Transfer']).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc19373d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['School'].duplicated().head() # 在Series上也可以使用"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da5d6d1",
   "metadata": {},
   "source": [
    "### 4. 替换函数\n",
    "一般而言，替换操作是针对某一个列进行的，因此下面的例子都以`Series`举例。`pandas`中的替换函数可以归纳为三类：映射替换、逻辑替换、数值替换。其中映射替换包含`replace`方法、第八章中的`str.replace`方法以及第九章中的`cat.codes`方法，此处介绍`replace`的用法。\n",
    "\n",
    "在`replace`中，可以通过字典构造，或者传入两个列表来进行替换："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f646212c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Gender'].replace({'Female':0, 'Male':1}).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d832d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Gender'].replace(['Female', 'Male'], [0, 1]).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c587de1d",
   "metadata": {},
   "source": [
    "另外，`replace`还有一种特殊的方向替换，指定`method`参数为`ffill`则为用前面一个最近的未被替换的值进行替换，`bfill`则使用后面最近的未被替换的值进行替换。从下面的例子可以看到，它们的结果是不同的："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f489f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series(['a', 1, 'b', 2, 1, 1,'a'])\n",
    "s.replace([1, 2], method='ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33948a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "s.replace([1, 2], method='bfill')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f32dadd7",
   "metadata": {},
   "source": [
    "#### 【WARNING】正则替换请使用`str.replace`\n",
    "\n",
    "虽然对于`replace`而言可以使用正则替换，但是当前版本下对于`string`类型的正则替换还存在`bug`，因此如有此需求，请选择`str.replace`进行替换操作。\n",
    "\n",
    "逻辑替换包括了`where`和`mask`，这两个函数是完全对称的：`where`函数在传入条件为`False`的对应行进行替换，而`mask`在传入条件为`True`的对应行进行替换，当不指定替换值时，替换为缺失值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c519b401",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series([-1, 1.2345, 100, -50])\n",
    "s.where(s<0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91daf321",
   "metadata": {},
   "outputs": [],
   "source": [
    "s.where(s<0, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8710ac58",
   "metadata": {},
   "outputs": [],
   "source": [
    "s.mask(s<0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49536067",
   "metadata": {},
   "outputs": [],
   "source": [
    "s.mask(s<0, -50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03772b9",
   "metadata": {},
   "source": [
    "需要注意的是，传入的条件只需是与被调用的`Series`索引一致的布尔序列即可："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3e3997",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_condition=pd.Series([True, False, False, True], index=s.index)\n",
    "s.mask(s_condition, -50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7993ba59",
   "metadata": {},
   "source": [
    "数值替换包含了`round`,`abs`,`clip`方法，它们分别表示按照给定精度四舍五入、取绝对值和截断："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2211a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series([-1, 1.2345, 100, -50])\n",
    "s.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845f183d",
   "metadata": {},
   "outputs": [],
   "source": [
    "s.abs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd387f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "s.clip(0, 2) # 前两个数分别表示上下截断边界"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d309086",
   "metadata": {},
   "source": [
    "### 5. 排序函数\n",
    "排序共有两种方式，其一为值排序，其二为索引排序，对应的函数是`sort_values`和`sort_index`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6582f52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_demo = df[['Grade', 'Name', 'Height','Weight']].set_index(['Grade', 'Name'])\n",
    "df_demo.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "054a923c",
   "metadata": {},
   "source": [
    "对身高进行排序，默认参数`ascending=True`为升序："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2461a991",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_demo.sort_values('Height').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c21a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_demo.sort_values('Height', ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ffbc51",
   "metadata": {},
   "source": [
    "在排序中，经常遇到多列排序的问题，比如在体重相同的情况下，对身高进行排序，并且保持身高降序排列，体重升序排列："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e508c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_demo.sort_values(['Weight', 'Height'], ascending=[True, False]).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "695d7186",
   "metadata": {},
   "source": [
    "索引排序的用法和值排序完全一致，只不过元素的值在索引中，此时需要指定索引层的名字或者层号，用参数`level`表示。另外，需要注意的是字符串的排列顺序由字母顺序决定。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ba6d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_demo.sort_index(level=['Grade', 'Name'], ascending=[True, False]).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6dfd27a",
   "metadata": {},
   "source": [
    "### 6. apply方法\n",
    "`apply`方法常用于`DataFrame`的行迭代或者列迭代，它的`axis`含义与第2小节中的统计聚合函数一致，`apply`的参数往往是一个以序列为输入的函数。例如对于`.mean()`，使用`apply`可以如下地写出："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b25469",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_demo = df[['Height', 'Weight']]\n",
    "def my_mean(x):\n",
    "    res = x.mean()\n",
    "    return res\n",
    "\n",
    "df_demo.apply(my_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03dfce6",
   "metadata": {},
   "source": [
    "同样的，可以利用`lambda`表达式使得书写简洁，这里的`x`就指代被调用的`df_demo`表中逐个输入的序列："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9474ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_demo.apply(lambda x:x.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e317fb44",
   "metadata": {},
   "source": [
    "若指定`axis=1`，那么每次传入函数的就是行元素组成的`Series`，其结果与之前的逐行均值结果一致。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7713b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_demo.apply(lambda x:x.mean(), axis=1).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d88a9e21",
   "metadata": {},
   "source": [
    "这里再举一个例子：`mad`函数返回的是一个序列中偏离该序列均值的绝对值大小的均值，例如序列1,3,7,10中，均值为5.25，每一个元素偏离的绝对值为4.25,2.25,1.75,4.75，这个偏离序列的均值为3.25。现在利用`apply`计算升高和体重的`mad`指标："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b48968d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_demo.apply(lambda x:(x-x.mean()).abs().mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bfa50db",
   "metadata": {},
   "source": [
    "这与使用内置的`mad`函数计算结果一致："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4f346b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_demo.mad()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d068f5c1",
   "metadata": {},
   "source": [
    "#### 【WARNING】谨慎使用`apply`\n",
    "得益于传入自定义函数的处理，`apply`的自由度很高，但这是以性能为代价的。一般而言，使用`pandas`的内置函数处理和`apply`来处理同一个任务，其速度会相差较多，因此只有在确实存在自定义需求的情境下才考虑使用`apply`。\n",
    "\n",
    "## 四、窗口对象\n",
    "`pandas`中有3类窗口，分别是滑动窗口`rolling`、扩张窗口`expanding`以及指数加权窗口`ewm`。\n",
    "\n",
    "### 1. 滑窗对象\n",
    "要使用滑窗函数，就必须先要对一个序列使用`.rolling`得到滑窗对象，其最重要的参数为窗口大小`window`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43b0d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series([1, 2, 3, 4, 5])\n",
    "roller = s.rolling(window = 3)\n",
    "roller"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7814bd",
   "metadata": {},
   "source": [
    "在得到了滑窗对象后，能够使用相应的聚合函数进行计算，需要注意的是窗口包含当前行所在的元素，例如在第四个位置进行均值运算时，应当计算(2+3+4)/3，而不是(1+2+3)/3："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a131a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "roller.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8736ca9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "roller.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9599277e",
   "metadata": {},
   "source": [
    "对于滑动相关系数或滑动协方差的计算，可以如下写出："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e3ef77",
   "metadata": {},
   "outputs": [],
   "source": [
    "s2 = pd.Series([1, 2, 6, 16, 30])\n",
    "roller.cov(s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c56443d",
   "metadata": {},
   "outputs": [],
   "source": [
    "roller.corr(s2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d461e7",
   "metadata": {},
   "source": [
    "此外，还支持使用`apply`传入自定义函数，其传入值是对应窗口的`Series`,例如上述的均值函数可以等效表示："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71fc996f",
   "metadata": {},
   "outputs": [],
   "source": [
    "roller.apply(lambda x:x.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38adfe36",
   "metadata": {},
   "source": [
    "`shift`, `diff`,`pct_change`是一组类滑窗函数，它们的公共参数为`periods=n`，默认为1，分别表示取向前第`n`个元素的值、与向前第`n`个元素做差（与`Numpy`中不同，后者表示`n`阶差分）、与向前第`n`个元素相比计算增长率。这里的`n`可以为负，表示反方向的类似操作。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1f6733",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series([1, 3, 6, 10, 15])\n",
    "s.shift(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ba5d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "s.diff(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f63581",
   "metadata": {},
   "outputs": [],
   "source": [
    "s.pct_change()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc04281",
   "metadata": {},
   "outputs": [],
   "source": [
    "s.shift(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf18a86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "s.diff(-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aff4354",
   "metadata": {},
   "source": [
    "将其视作类滑窗函数的原因是，它们的功能可以用窗口大小为`n+1`的`rolling`方法等价代替："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155a3e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "s.rolling(3).apply(lambda x:list(x)[0]) # s.shift(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad97f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "s.rolling(4).apply(lambda x:list(x)[-1]-list(x)[0]) # s.diff(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5992fb44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_pct(x):\n",
    "    L = list(x)\n",
    "    return L[-1]/L[0]-1\n",
    "\n",
    "s.rolling(2).apply(my_pct) # s.pct_change()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d5b994",
   "metadata": {},
   "source": [
    "### 2. 扩张窗口\n",
    "扩张窗口又称累计窗口，可以理解为一个动态长度的窗口，其窗口的大小就是从序列开始处到具体操作的对应位置，其使用的聚合函数会作用于这些逐步扩张的窗口上。具体地说，设序列为a1, a2, a3, a4，则其每个位置对应的窗口即[a1]、[a1, a2]、[a1, a2, a3]、[a1, a2, a3, a4]。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80875be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series([1, 3, 6, 10])\n",
    "s.expanding().mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
