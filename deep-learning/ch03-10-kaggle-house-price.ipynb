{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb55c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "import os\n",
    "import tarfile\n",
    "import zipfile\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from d2l import torch as d2l\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d25cb57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @save\n",
    "DATA_HUB = dict()\n",
    "DATA_URL = 'http://d2l-data.s3-accelerate.amazonaws.com/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1fc281c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download(name, cache_dir=os.path.join('..', 'data')): # @save\n",
    "    \"\"\"下载一个DATA_HUB中的文件，返回本地文件名\"\"\"\n",
    "    assert name in DATA_HUB, f\"{name} 不存在于 {DATA_HUB}\"\n",
    "    url, sha1_hash = DATA_HUB[name]\n",
    "    os.makedirs(cache_dir, exist_ok=True)\n",
    "    fname = os.path.join(cache_dir, url.split('/')[-1])\n",
    "    if os.path.exists(fname):\n",
    "        sha1 = hashlib.sha1()\n",
    "        with open(fname, 'rb') as f:\n",
    "            while True:\n",
    "                data = f.read(1048576)\n",
    "                if not data:\n",
    "                    break\n",
    "                sha1.update(data)\n",
    "        if sha1.hexdigest() == sha1_hash:\n",
    "            return fname  # 命中缓存\n",
    "    \n",
    "    print(f'正在从{url}下载{fname}...')\n",
    "    r = requests.get(url, stream=True, verify=True)\n",
    "    with open(fname, 'wb') as f:\n",
    "        f.write(r.content)\n",
    "    return fname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ef5b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_extract(name, folder=None):  # @save\n",
    "    \"\"\"下载并解压zip/tar文件\"\"\"\n",
    "    fname = download(name)\n",
    "    base_dir = os.path.dirname(fname)\n",
    "    data_dir, ext = os.path.splitext(fname)\n",
    "    if ext == '.zip':\n",
    "        fp = zipfile.ZipFile(fname, 'r')\n",
    "    elif ext in ('.tar', '.gz'):\n",
    "        fp = tarfile.open(fname, 'r')\n",
    "    else:\n",
    "        assert False, '只有zip/tar文件可以被解压缩'\n",
    "\n",
    "    fp.extractall(base_dir)\n",
    "    return os.path.join(base_dir, folder) if folder else data_dir \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4543f71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_all():# @save\n",
    "    \"\"\"下载DATA_HUB中的所有文件\"\"\"\n",
    "    for name in DATA_HUB:\n",
    "        download(name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4edbf307",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 下载数据集\n",
    "DATA_HUB['kaggle_house_train'] = (# @save\n",
    "    DATA_URL + 'kaggle_house_pred_train.csv',\n",
    "    '585e9cc93e70b39160e7921475f9bcd7d31219ce'\n",
    ")\n",
    "\n",
    "DATA_HUB['kaggle_house_test'] = (# @save\n",
    "    DATA_URL + 'kaggle_house_pred_test.csv',\n",
    "    'fa19780a7b011d9b009e8bff8e99922a8ee2eb90'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb58898e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取数据集\n",
    "train_data = pd.read_csv(download('kaggle_house_train'))\n",
    "test_data = pd.read_csv(download('kaggle_house_test'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fafd5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_data.shape)\n",
    "print(test_data.shape)\n",
    "print(train_data.iloc[0:4, [0, 1, 2, 3, -3, -2, -1]]) # 打印数据集中前4行的正数4列和倒数3列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3d17d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 第一列特征是ID,不携带任何用于预测的信息,删除样本中的第一列和最后一列（SalePrice）\n",
    "all_features = pd.concat((train_data.iloc[:, 1:-1], test_data.iloc[:, 1:]))\n",
    "print(all_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3b3564",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 找出那些是数值的列\n",
    "numeric_features = all_features.dtype[all_features.dtypes != 'object'].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55761490",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(numeric_features)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
