{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013e53b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "from d2l import torch as d2l\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e19e653",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44704274",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        nn.init.normal_(m.weight, std=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98945345",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_inputs, num_outputs, num_hidden1, num_hidden2 = 784, 10, 256, 256\n",
    "dropout1, dropout2 = 0.2, 0.5\n",
    "\n",
    "net = nn.Sequential(nn.Flatten(), nn.Linear(784, 256), nn.ReLU(),\n",
    "                    # 在第一个全连接层之后添加一个dropout层\n",
    "                    nn.Dropout(dropout1), nn.Linear(256, 256), nn.ReLU(),\n",
    "                    # 在第二个全连接层之后添加一个dropout层\n",
    "                    nn.Dropout(dropout2), nn.Linear(256, 10))\n",
    "\n",
    "net.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f72e252",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs, lr, batch_size = 10, 0.5, 256\n",
    "loss = nn.CrossEntropyLoss()\n",
    "train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size)\n",
    "trainer = torch.optim.SGD(net.parameters(), lr=lr)\n",
    "d2l.train_ch3(net, train_iter, test_iter, loss, num_epochs, trainer)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
