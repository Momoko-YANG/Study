{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d3f48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from d2l import torch as d2l\n",
    "\n",
    "import d2lutil.common as common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a9ac3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c69dcc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train, n_test, num_inputs = 20, 100, 200\n",
    "true_w, true_b = torch.ones(num_inputs, 1) * 0.01, 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7561181e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 人造数据集\n",
    "features = torch.randn((n_train + n_test, num_inputs))\n",
    "labels = torch.matmul(features, true_w) + true_b\n",
    "labels += torch.tensor(np.random.normal(0, 0.01, size=labels.size()), dtype=torch.float)\n",
    "train_features, test_features = features[:n_train, :], features[n_train:, :]\n",
    "train_labels, test_labels = labels[:n_train], labels[n_train:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8add7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成随机训练数据集\n",
    "batch_size, num_epochs, lr = 1, 100, 0.003\n",
    "dataset = torch.utils.data.TensorDataset(train_features, train_labels)\n",
    "train_iter = torch.utils.data.DataLoader(dataset, batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f63e3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_params():\n",
    "    w = torch.normal(0, 1, size=(num_inputs, 1), requires_grad=True)\n",
    "    b = torch.zeros(1, requires_grad=True)\n",
    "    return[w, b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab969091",
   "metadata": {},
   "outputs": [],
   "source": [
    "def l2_penalty(w):\n",
    "    return torch.sum(w.pow(2)) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee5d318",
   "metadata": {},
   "outputs": [],
   "source": [
    "net, loss = d2l.linreg, d2l.squared_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e957d070",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_and_plot(lambd):\n",
    "    w, b = init_params()\n",
    "    train_ls, test_ls = [], []\n",
    "\n",
    "    for _ in range(num_epochs):\n",
    "        for X, y in train_iter:\n",
    "\n",
    "            l = loss(net(X, w, b), y) + lambd * l2_penalty(w)\n",
    "            l = l.sum()\n",
    "            if w.grad is not None:\n",
    "                w.grad.data.zero_()\n",
    "                b.grad.data.zero_()\n",
    "            l.backward()\n",
    "            d2l.sgd([w, b], lr, batch_size)\n",
    "        \n",
    "        train_ls.append(loss(net(train_features, w, b), train_labels).mean().item())\n",
    "        test_ls.append(loss(net(test_features, w, b), test_labels).mean().item())\n",
    "    \n",
    "    common.semilogy(range(1, num_epochs + 1), train_ls, 'epochs', 'loss',\n",
    "                    range(1, num_epochs + 1), test_ls, ['train', 'test'])\n",
    "    print('L2 norm of w:', w.norm().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da75abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 无权重衰减\n",
    "fit_and_plot(lambd=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949375d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 权重衰减\n",
    "fit_and_plot(lambd=3)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
